{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from epimodel.pymc3_models.cm_effect.datapreprocessor import DataPreprocessor\n",
    "from os import walk\n",
    "\n",
    "import re\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "fp2 = FontProperties(fname=r\"../../fonts/Font Awesome 5 Free-Solid-900.otf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPreprocessor(drop_HS=True)\n",
    "data = dp.preprocess_data(\"double_entry_final.csv\", last_day=\"2020-05-30\", schools_unis=\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_res = pickle.load(open(\"final_full.pkl\", \"rb\")).CMReduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"../../server/additional_exps\"\n",
    "\n",
    "def load_exp(exp_num, local=False):\n",
    "    if not local:\n",
    "        return pickle.load(open(f\"{exp_dir}/exp_{exp_num}.pkl\", \"rb\"))\n",
    "    else:\n",
    "        return pickle.load(open(f\"../../additional_exps/exp_{exp_num}.pkl\", \"rb\"))\n",
    "\n",
    "colors = [*sns.color_palette(\"colorblind\"), *sns.color_palette(\"bright\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_features = [ #()\"Healthcare Infection Control\", [0]),\n",
    " (\"Mask-wearing mandatory in\\n(some) public spaces\", [0]),\n",
    " (\"Gatherings limited to 1000\\npeople or less\", [1]),\n",
    " (\"Gatherings limited to 100\\npeople or less\", [2, 1]),\n",
    " (\"Gatherings limited to 10\\npeople or less\", [3, 2, 1]),\n",
    " (\"Some businesses closed\", [4]),\n",
    " (\"Most businesses closed\", [4, 5]),\n",
    " (\"Schools and universities closed\", [6, 7]),\n",
    " (\"Stay-at-home order\\n(with exemptions)\", [8]),\n",
    " ]\n",
    "\n",
    "\n",
    "# derived_features = [ #()\"Healthcare Infection Control\", [0]),\n",
    "#  (\"Mask-wearing mandatory in\\n(some) public spaces\", [0]),\n",
    "#  (\"Gatherings limited to 1000\\npeople or less\", [1]),\n",
    "#  (\"Gatherings limited to 100\\npeople or less\", [2]),\n",
    "#  (\"Gatherings limited to 10\\npeople or less\", [3]),\n",
    "#  (\"Some businesses closed\", [4]),\n",
    "#  (\"Most businesses closed\", [5]),\n",
    "#  (\"Schools and universities closed\", [6, 7]),\n",
    "#  (\"Stay-at-home order\\n(with exemptions)\", [8]),\n",
    "#  ]\n",
    "\n",
    "cm_plot_style = [\n",
    "#             (\"\\uf7f2\", \"tab:red\"), # hospital symbol\n",
    "            (\"\\uf963\", \"black\"), # mask\n",
    "            (\"\\uf0c0\", \"darkgrey\"), # ppl\n",
    "            (\"\\uf0c0\", \"dimgrey\"), # ppl\n",
    "            (\"\\uf0c0\", \"black\"), # ppl\n",
    "            (\"\\uf07a\", \"tab:orange\"), # shop 1\n",
    "            (\"\\uf07a\", \"tab:red\"), # shop2\n",
    "            (\"\\uf549\", \"black\"), # school\n",
    "            (\"\\uf19d\", \"black\"), # university\n",
    "            (\"\\uf965\", \"black\") # home\n",
    "]\n",
    "\n",
    "def produce_ranges(trace):\n",
    "    means = np.mean(trace, axis=0)\n",
    "    med = np.median(trace, axis=0)\n",
    "    li = np.percentile(trace, 2.5, axis=0)\n",
    "    ui = np.percentile(trace, 97.5, axis=0)\n",
    "    lq = np.percentile(trace, 25, axis=0)\n",
    "    uq = np.percentile(trace, 75, axis=0)\n",
    "    return means, med, li, ui, lq, uq\n",
    "\n",
    "def add_trace_to_plot(res, y_off, col, label, alpha, width, size=8, zeros=None):\n",
    "    nS, _ = res.shape\n",
    "    nF = len(derived_features)\n",
    "    derived_samples = np.zeros((nS, nF))\n",
    "\n",
    "    for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "        samples = np.ones(nS)\n",
    "        for r in prodrows:\n",
    "            samples = samples * res[:, r] \n",
    "        derived_samples[:, f_i] = samples\n",
    "\n",
    "    res = derived_samples\n",
    "    res = 100*(1-res)\n",
    "    \n",
    "    if zeros is not None:\n",
    "        for z in zeros:\n",
    "            if z < nF:\n",
    "                res[:, z] = 1e5\n",
    "    \n",
    "    y_vals = -1 * np.arange(nF)\n",
    "    plt.plot([100], [100], color=col, linewidth=1, alpha=alpha, label=label)\n",
    "    mn, med, li, ui, lq, uq = produce_ranges(res)\n",
    "    plt.scatter(med, y_vals+y_off, marker=\"|\", color=col, s=size, alpha=alpha)\n",
    "    for cm in range(nF):\n",
    "        if cm > 7:\n",
    "            plt.plot([li[cm], ui[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.25*0.25, linewidth=width, linestyle=\"--\")\n",
    "            plt.plot([lq[cm], uq[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.75*0.25, linewidth=width, linestyle=\"--\")\n",
    "        else:\n",
    "            plt.plot([li[cm], ui[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.25, linewidth=width)\n",
    "            plt.plot([lq[cm], uq[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.75, linewidth=width)\n",
    "        \n",
    "def setup_large_plot(y_ticks = True, icons = True, xlabel=True):\n",
    "    nF = len(derived_features)\n",
    "    ax = plt.gca()\n",
    "    x_min = -50\n",
    "    x_max = 100\n",
    "    plt.plot([0, 0], [1, -(nF)], \"--k\", linewidth=0.5)\n",
    "    xrange = np.array([x_min, x_max])\n",
    "    for height in range(0, nF+2, 2):\n",
    "        plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "    xtick_vals = [-50, -25, 0, 25, 50, 75, 100]\n",
    "    xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "    if y_ticks:\n",
    "        plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "        yax = ax.get_yaxis()\n",
    "        yax.set_tick_params(pad=140)\n",
    "        \n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    x_r = np.abs(x_min - x_max)\n",
    "    plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([-(nF - 0.25), 0.75])\n",
    "    \n",
    "    if icons:\n",
    "        for cm in range(len(derived_features)):\n",
    "            for i, val in enumerate(derived_features[cm][1]):\n",
    "                plt.text(x_min - 7.5 - 8*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                             fontproperties=fp2, fontsize=8, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "                \n",
    "    if xlabel:\n",
    "        plt.xlabel(\"Average additional reduction in $R$, in the context of our data\", fontsize=8)\n",
    "        \n",
    "def setup_larger_plot(y_ticks = True, icons = True, xlabel=True):\n",
    "    nF = len(derived_features)\n",
    "    ax = plt.gca()\n",
    "    x_min = -50\n",
    "    x_max = 100\n",
    "    plt.plot([0, 0], [1, -(nF)], \"--k\", linewidth=0.5)\n",
    "    xrange = np.array([x_min, x_max])\n",
    "    for height in range(0, nF+2, 2):\n",
    "        plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "    xtick_vals = [-50, -25, 0, 25, 50, 75, 100]\n",
    "    xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "    if y_ticks:\n",
    "        plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "        yax = ax.get_yaxis()\n",
    "        yax.set_tick_params(pad=140)\n",
    "        \n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    x_r = np.abs(x_min - x_max)\n",
    "    plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([-(nF - 0.25), 0.75])\n",
    "    \n",
    "    if icons:\n",
    "        for cm in range(len(derived_features)):\n",
    "            for i, val in enumerate(derived_features[cm][1]):\n",
    "                plt.text(x_min - 7.5 - 9*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                             fontproperties=fp2, fontsize=12, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "                \n",
    "    if xlabel:\n",
    "        plt.xlabel(\"Average additional reduction in $R$, in the context of our data\", fontsize=8)\n",
    "    \n",
    "def setup_small_plot(y_ticks = True, icons = True, xlabel=True):\n",
    "    nF = len(derived_features)\n",
    "    ax = plt.gca()\n",
    "    x_min = -50\n",
    "    x_max = 100\n",
    "    plt.plot([0, 0], [1, -(nF)], \"--k\", linewidth=0.5)\n",
    "    xrange = np.array([x_min, x_max])\n",
    "    for height in range(0, nF+2, 2):\n",
    "        plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "    xtick_vals = [-50, 0, 50, 100]\n",
    "    xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "    if y_ticks:\n",
    "        plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "        yax = ax.get_yaxis()\n",
    "        yax.set_tick_params(pad=140)\n",
    "        \n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    x_r = np.abs(x_min - x_max)\n",
    "    plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([-(nF - 0.25), 0.75])\n",
    "    \n",
    "    if icons:\n",
    "        for cm in range(len(derived_features)):\n",
    "            for i, val in enumerate(derived_features[cm][1]):\n",
    "                plt.text(x_min - 7.5 - 13*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                             fontproperties=fp2, fontsize=8, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "                \n",
    "    if xlabel:\n",
    "        plt.xlabel(\"Average additional reduction in $R$, in the context of our data\", fontsize=8)\n",
    "        \n",
    "class ResultsObject():\n",
    "    def __init__(self, indx, trace):\n",
    "        self.CMReduction = trace.CMReduction\n",
    "        self.RegionR = trace.RegionR[:, indx]\n",
    "        self.InfectedCases = trace.InfectedCases[:, indx, :]\n",
    "        self.InfectedDeaths = trace.InfectedDeaths[:, indx, :]\n",
    "        self.ExpectedCases = trace.ExpectedCases[:, indx, :]\n",
    "        self.ExpectedDeaths = trace.ExpectedDeaths[:, indx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nCMs = 9\n",
    "\n",
    "def grab_traces_categorised(fname, verbose=False):\n",
    "    global default_res\n",
    "    \n",
    "    files_found = 0\n",
    "    all_traces = []\n",
    "    cat_sen = defaultdict(list)\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(walk(fname)):\n",
    "        for f in filenames:\n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f and \"base\" not in f:\n",
    "                    \n",
    "                trace = np.loadtxt(dirpath+\"/\"+f)\n",
    "                nS, f_nCMs = trace.shape\n",
    "                \n",
    "                if f_nCMs > nCMs:\n",
    "                    trace = trace[:, :nCMs]\n",
    "                elif f_nCMs < nCMs:\n",
    "                    leaveout_num = int(f[-5])\n",
    "                    full_trace = np.zeros((nS, nCMs))\n",
    "                    full_trace[:, :leaveout_num] = trace[:, :leaveout_num]\n",
    "#                     full_trace[:, leaveout_num] = default_res[:, leaveout_num]\n",
    "                    full_trace[:, leaveout_num] = np.ones(nS)\n",
    "                    full_trace[:, (leaveout_num+1):] = trace[:, leaveout_num:]\n",
    "                    trace = full_trace\n",
    "                \n",
    "                files_found += 1\n",
    "                \n",
    "                res = trace\n",
    "                    \n",
    "                if \"additive\" in fname:\n",
    "                    res = 1 - res\n",
    "                    \n",
    "                if \"delay_mean_death\" in f: \n",
    "                    cat_sen[\"Death Delay\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                \n",
    "                    if verbose:\n",
    "                        print(f\"delays added {f}\")\n",
    "                \n",
    "                elif  \"delay_mean_confirmed\" in f: \n",
    "                    cat_sen[\"Cases Delay\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                \n",
    "                    if verbose:\n",
    "                        print(f\"delays added {f}\")\n",
    "                    \n",
    "                elif \"serial_int\" in f: \n",
    "                    cat_sen[\"Serial Interval\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"si added {f}\")\n",
    "                    \n",
    "                elif \"leavout\" in f: \n",
    "                    cat_sen[\"NPI Leaveouts\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"leavouts added {f}\")\n",
    "                \n",
    "                elif \"R_hyperprior\" in f: \n",
    "                    cat_sen[\"R Priors\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"epi prior {f}\")\n",
    "                        \n",
    "                elif \"cm_prior\" in f: \n",
    "                    cat_sen[\"NPI Priors\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"epi prior {f}\")\n",
    "                        \n",
    "                elif \"noise\" in f and \"no_noise\" not in f: \n",
    "                    cat_sen[\"Hyperparameter\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"hypers added {f}\")\n",
    "                        \n",
    "                elif \"regions_heldout\" in f or \"regholdout\" in f: \n",
    "                    cat_sen[\"Region Holdouts\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"reg holdouts added {f}\")\n",
    "                    \n",
    "                elif \"schools\" in f: \n",
    "                    cat_sen[\"SE Schools\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"mob added {f}\")\n",
    "                    \n",
    "                elif \"min_confirmed\" in f: \n",
    "                    cat_sen[\"Minimum Confirmed Cases\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"min conf added {f}\")\n",
    "                        \n",
    "                elif \"min_deaths\" in f: \n",
    "                    cat_sen[\"Minimum Deaths\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"min deaths added {f}\")\n",
    "                        \n",
    "                elif \"smoothing\" in f: \n",
    "                    cat_sen[\"Smoothing\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"smooting {f}\")\n",
    "                \n",
    "                elif \"mobility\" in f: \n",
    "                    cat_sen[\"Mobility\"].append((f, res))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"min conf added {f}\")\n",
    "                else:\n",
    "                    print(f\"File {f} not added - no category found\")\n",
    "        \n",
    "    return cat_sen\n",
    "\n",
    "def fname_to_label(f):\n",
    "    if \"regholdout\" in f:\n",
    "        return f[:2]\n",
    "    \n",
    "    if \"regions_heldout\" in f:\n",
    "        return f[16:18]\n",
    "    \n",
    "    if \"cm_prior\" in f:\n",
    "        if \"wide\" in f:\n",
    "            return \"Wide\"\n",
    "        \n",
    "        if \"half_normal\" in f:\n",
    "            return \"Half Normal\"\n",
    "        \n",
    "        if \"icl\" in f:\n",
    "            return \"Flaxman et. al.\"\n",
    "    \n",
    "    if \"data_mobility\" in f:\n",
    "        if \"no_work\" in f:\n",
    "            return \"Retail & Recreation\"\n",
    "        elif \"rec_work\" in f:\n",
    "            return \"Workplace & Retail &\\nRecreation\"\n",
    "    \n",
    "    if \"R_hyperprior\" in f:\n",
    "        if \"0\" in f:\n",
    "            return \"$\\mu=2.5$\"\n",
    "        elif \"1\" in f:\n",
    "            return \"$\\mu=4.5$\"\n",
    "    \n",
    "    if \"schools_open\" in f:\n",
    "        return \"SE Schools Open\"\n",
    "\n",
    "    if \"delay\" in f and \"confirmed\" in f:\n",
    "         if \"0\" in f:\n",
    "            return \"$-4$ days\"\n",
    "         if \"1\" in f:\n",
    "            return \"$-2$ days\" \n",
    "         if \"2\" in f:\n",
    "            return \"$+2$ days\" \n",
    "         if \"3\" in f and \"v3\" not in f:\n",
    "            return \"$+4$ days\" \n",
    "    \n",
    "    if \"delay\" in f and \"death\" in f:\n",
    "         if \"0\" in f:\n",
    "            return \"$-4$ days\"\n",
    "         if \"1\" in f:\n",
    "            return \"$-2$ days\" \n",
    "         if \"2\" in f:\n",
    "            return \"$+2$ days\" \n",
    "         if \"3\" in f and \"v3\" not in f:\n",
    "            return \"$+4$ days\" \n",
    "\n",
    "    if \"cm_leavout\" in f:\n",
    "        if \"0\" in f:\n",
    "            return \"Mask Wearing\"\n",
    "        if \"1\" in f:\n",
    "            return \"Gatherings <1000\"\n",
    "        if \"2\" in f and \"v3\" not in f:\n",
    "            return \"Gatherings <100\"\n",
    "        if \"3\" in f:\n",
    "            return \"Gatherings <10\"\n",
    "        if \"4\" in f:\n",
    "            return \"Some Businesses Suspended\"\n",
    "        if \"5\" in f:\n",
    "            return \"Most Businesses Suspended\"\n",
    "        if \"6\" in f:\n",
    "            return \"School Closure\"\n",
    "        if \"7\" in f:\n",
    "            return \"University Closure\"\n",
    "        if \"8\" in f:\n",
    "            return \"Stay at Home Order\"\n",
    "        \n",
    "    if \"serial_int\" in f:\n",
    "        if \"SI4\" in f:\n",
    "            return \"$\\mu=4$\"\n",
    "        if \"SI5\" in f:\n",
    "            return \"$\\mu=5$\"\n",
    "        if \"SI6\" in f:\n",
    "            return \"$\\mu=6$\"\n",
    "        if \"SI7\" in f:\n",
    "            return \"$\\mu=7$\"\n",
    "        if \"SI8\" in f:\n",
    "            return \"$\\mu=8$\"\n",
    "    \n",
    "    if \"min_confirmed\" in f:\n",
    "        if \"v3\" in f:\n",
    "            val = re.findall('\\\\d+', f)[1]\n",
    "        else:\n",
    "            val = re.findall('\\\\d+', f)[0]\n",
    "        return f\"{val}\"\n",
    "    \n",
    "    if \"min_deaths\" in f:\n",
    "        if \"v3\" in f:\n",
    "            val = re.findall('\\\\d+', f)[1]\n",
    "        else:\n",
    "            val = re.findall('\\\\d+', f)[0]\n",
    "        return f\"{val}\"\n",
    "    \n",
    "    if \"cm_prior_combined_additive\" in f:\n",
    "        if \"10\" in f:\n",
    "            return \"$\\\\alpha_i\\sim$Dirichlet($\\\\alpha=10$)\"\n",
    "        if \"5\" in f:\n",
    "            return \"$\\\\alpha_i\\sim$Dirichlet($\\\\alpha=5$)\"\n",
    "    \n",
    "    if \"smoothing\" in f:\n",
    "        if \"v3\" in f:\n",
    "            val = re.findall('\\\\d+', f)[1]\n",
    "        else:\n",
    "            val = re.findall('\\\\d+', f)[0]\n",
    "        return f\"{val} days\"\n",
    "    \n",
    "    if \"growth_noise\" in f and \"0\" in f:\n",
    "        return \"$\\sigma_n=0.05$\"\n",
    "    \n",
    "    if \"growth_noise\" in f and \"1\" in f:\n",
    "        return \"$\\sigma_n=0.1$\"\n",
    "    \n",
    "    if \"growth_noise\" in f and \"2\" in f:\n",
    "        return \"$\\sigma_n=0.4$\"\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sen = grab_traces_categorised(\"../../server/traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category 1: Structural Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_add = 1\n",
    "exp_noisyr = 2\n",
    "exp_diff = 3\n",
    "exp_dr = 4\n",
    "\n",
    "res_add = load_exp(exp_add)\n",
    "res_noisyr = load_exp(exp_noisyr, local=True)\n",
    "res_diff = load_exp(exp_diff)\n",
    "res_dr = load_exp(exp_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 3), dpi=300)\n",
    "\n",
    "setup_large_plot()\n",
    "\n",
    "y_off = -np.linspace(-0.3, 0.3, 5)\n",
    "width = 1\n",
    "add_trace_to_plot(1-res_add.CMReduction, y_off[0], colors[0], \"Additive\", 1, width) \n",
    "add_trace_to_plot(res_noisyr.CMReduction, y_off[1], colors[1], \"Noisy-R\", 1, width) \n",
    "add_trace_to_plot(res_diff.CMReduction, y_off[2], colors[2], \"Different Effects\", 1, width)\n",
    "add_trace_to_plot(res_dr.CMReduction, y_off[3], colors[3], \"Discrete Renewal\", 1, width)\n",
    "add_trace_to_plot(default_res, y_off[4], \"k\", \"Default\", 1, width) \n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.2, 1.01), fontsize=6)\n",
    "plt.title(\"Structural Sensitivity\", fontsize=\"10\")\n",
    "\n",
    "plt.savefig(f\"FigSSAMain.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category 2: Unobserved Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_travel = 5\n",
    "exp_transport = 6\n",
    "exp_int_movement = 7\n",
    "exp_info = 8\n",
    "exp_testing = 9\n",
    "\n",
    "exp_schools_uni = 20\n",
    "\n",
    "\n",
    "res_travel = load_exp(exp_travel)\n",
    "res_transport = load_exp(exp_transport)\n",
    "res_int_movement = load_exp(exp_int_movement)\n",
    "res_info = load_exp(exp_info)\n",
    "res_testing = load_exp(exp_testing)\n",
    "\n",
    "res_su = load_exp(exp_schools_uni, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 3), dpi=300)\n",
    "\n",
    "plt.subplot(121)\n",
    "setup_large_plot(xlabel=False)\n",
    "\n",
    "y_off = -np.linspace(-0.3, 0.3, 6)\n",
    "width = 1\n",
    "add_trace_to_plot(res_travel.CMReduction[:, :9], y_off[0], colors[0], \"Travel Screening/Bans\", 1, width) \n",
    "add_trace_to_plot(res_transport.CMReduction[:, :9], y_off[1], colors[1], \"Public Transport Limited\", 1, width) \n",
    "add_trace_to_plot(res_int_movement.CMReduction[:, :9], y_off[2], colors[2], \"Internal Movement Limited\", 1, width)\n",
    "add_trace_to_plot(res_info.CMReduction[:, :9], y_off[3], colors[3], \"Public Information Campaigns\", 1, width)\n",
    "add_trace_to_plot(res_testing.CMReduction[:, [0, 2, 3, 4, 5, 6, 7, 8, 9]], y_off[4], colors[4], \"Symptomatic Testing\", 1, width)\n",
    "add_trace_to_plot(default_res, y_off[5], \"k\", \"Default\", 1, width) \n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.2, 1.01), fontsize=6)\n",
    "plt.title(\"Inclusion of OxCGRT NPIs\", fontsize=\"10\")\n",
    "\n",
    "plt.subplot(122)\n",
    "setup_large_plot(False)\n",
    "\n",
    "\n",
    "cat_sen[\"NPI Leaveouts\"].sort(key = lambda x: x[0])\n",
    "\n",
    "y_off = -np.linspace(-0.4, 0.4, len(cat_sen[\"NPI Leaveouts\"])+1)\n",
    "\n",
    "for i, (f, t) in enumerate(cat_sen[\"NPI Leaveouts\"]):\n",
    "    if i == 6 or i == 7:\n",
    "        add_trace_to_plot(t, y_off[i], colors[i], fname_to_label(f), 1, width, zeros=[6, i])\n",
    "    else:\n",
    "        add_trace_to_plot(t, y_off[i], colors[i], fname_to_label(f), 1, width, zeros=[i])\n",
    "cm_red = res_su.CMReduction\n",
    "nS, _ = cm_red.shape\n",
    "cm_red[:, 6] = np.ones(nS)\n",
    "cm_red[:, 7] = np.ones(nS)\n",
    "add_trace_to_plot(cm_red, y_off[-1], colors[-1], \"School and University Closure\", 1, width,  zeros=[6, 8, 9])\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.4, 1.01), fontsize=6)\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.4, 1.01), fontsize=6)\n",
    "plt.title(\"Exclusion of Collected NPIs\", fontsize=\"10\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"FigureUOB_main.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Main\" Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ho = load_exp(17, True)\n",
    "\n",
    "exp_active = 18\n",
    "exp_death = 19\n",
    "\n",
    "res_active = load_exp(exp_active)\n",
    "res_death = load_exp(exp_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.preprocess_data(\"../../notebooks/double-entry-data/double_entry_final.csv\", last_day=\"2020-05-30\",\n",
    "                                  schools_unis=\"whoops\")\n",
    "data.mask_region_ends()\n",
    "# and mask earlier if needed\n",
    "data.mask_reopenings(n_extra=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11.5, 9), dpi=300)\n",
    "\n",
    "gs = GridSpec(4, 4, figure=fig)\n",
    "ax1 = plt.subplot(gs.new_subplotspec((0, 0), colspan=2, rowspan=2))\n",
    "\n",
    "plt.plot([10**-1, 10**7], [10**-1, 10**7], \"--\", linewidth=0.5, color=\"black\")\n",
    "for indx, region in enumerate(data.Rs):\n",
    "    \n",
    "    dd = np.nonzero(data.NewDeaths.mask[indx, :])[0][0]+19\n",
    "    cd = np.nonzero(data.NewCases.mask[indx, :])[0][0]+19\n",
    "    \n",
    "    ed = res_ho.ExpectedDeaths[:, indx, dd]\n",
    "    ec = res_ho.ExpectedCases[:, indx, cd]\n",
    "    dist1 = pm.NegativeBinomial.dist(mu=ed , alpha=res_ho.Phi_1)\n",
    "    dist2 = pm.NegativeBinomial.dist(mu=ec , alpha=res_ho.Phi_1)\n",
    "    ec_output = dist2.random()\n",
    "    try:\n",
    "        ed_output = dist1.random()\n",
    "    except:\n",
    "        print(np.sum(ed))\n",
    "        print(f\"error with {region}\")\n",
    "        print(data.NewDeaths.data[indx, -dd])\n",
    "        ed_output = 1e-10\n",
    "\n",
    "    deaths = data.NewDeaths.data[indx, dd]\n",
    "    cases = data.NewCases.data[indx, cd]\n",
    "    if indx == 0:\n",
    "        plt.scatter(cases, np.median(ec_output), color=\"tab:blue\", label=\"Cases\", s=12)    \n",
    "        plt.scatter(deaths, np.median(ed_output), color=\"tab:red\", label=\"Deaths\", s=12)\n",
    "\n",
    "    plt.scatter(cases, np.median(ec_output), color=\"tab:blue\", s=12)\n",
    "    plt.scatter(deaths, np.median(ed_output), color=\"tab:red\", s=12)\n",
    "    plt.plot([cases, cases], [np.percentile(ec_output, 2.5), np.percentile(ec_output, 97.5)], color=\"tab:blue\", alpha=0.25, linewidth=2)\n",
    "    plt.plot([deaths, deaths], [np.percentile(ed_output, 2.5), np.percentile(ed_output, 97.5)], color=\"tab:red\", alpha=0.25, linewidth=2)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
    "plt.xlabel(\"Reported\", fontsize=10)\n",
    "plt.ylabel(\"Predicted\", fontsize=10)\n",
    "plt.title(f\"20 Day Extrapolation\", fontsize=12)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend(loc=\"upper left\", fancybox=True, shadow=True, fontsize=10)\n",
    "\n",
    "tick_vals = np.arange(6)-1\n",
    "plt.xticks(np.power(10.0, tick_vals), [f\"${np.power(10.0, loc):.0f}$\" if loc<2 else f\"$10^{loc}$\"  for loc in tick_vals], fontsize=10)\n",
    "plt.yticks(np.power(10.0, tick_vals), [f\"${np.power(10.0, loc):.0f}$\" if loc<2 else f\"$10^{loc}$\"  for loc in tick_vals], fontsize=10)\n",
    "plt.grid(False, which='major', axis='both')\n",
    "\n",
    "plt.xlim([10**-1, 10**4.5])\n",
    "plt.ylim([10**-1, 10**4.5])\n",
    "plt.minorticks_off()\n",
    "\n",
    "rows = [2, 3, 2, 3]\n",
    "cols = [0, 0, 1, 1]\n",
    "\n",
    "folds = [['DE', 'HU', 'FI', 'IE', 'RS', 'BE'],\n",
    "         ['DK', 'GR', 'NO', 'FR', 'RO', 'MA'],\n",
    "         ['ES', 'CZ', 'NL', 'CH', 'PT', 'AT'],\n",
    "         ['IL', 'SE', 'IT', 'MX', 'GB', 'PL']]\n",
    "\n",
    "class ResultsObject():\n",
    "    def __init__(self, indx, trace):\n",
    "        self.CMReduction = trace.CMReduction\n",
    "        self.RegionLogR = trace.RegionLogR[:, indx]\n",
    "        self.Z1C = trace.Z1C[:, indx, :]\n",
    "        self.Z1D = trace.Z1D[:, indx, :]\n",
    "        self.InfectedCases = trace.InfectedCases[:, indx, :]\n",
    "        self.InfectedDeaths = trace.InfectedDeaths[:, indx, :]\n",
    "        self.ExpectedCases = trace.ExpectedCases[:, indx, :]\n",
    "        self.ExpectedDeaths = trace.ExpectedDeaths[:, indx, :]\n",
    "    \n",
    "for s_i, (r,c) in enumerate(zip(rows, cols)):\n",
    "    plt.subplot(gs.new_subplotspec((r, c), colspan=1, rowspan=1))\n",
    "    setup_small_plot(False, xlabel=False)\n",
    "    y_off = np.linspace(-0.3, 0.3, len(folds[0]))\n",
    "    for r_i, r in enumerate(folds[s_i]):\n",
    "        res = pickle.load(open(f\"../../server/ho_results_final4/{r}.pkl\", \"rb\"))\n",
    "        add_trace_to_plot(res.CMReduction, y_off[r_i], colors[r_i], label=r, alpha=1, width=1, size=8)\n",
    "    plt.legend(fontsize=6, loc=\"upper left\", bbox_to_anchor=(0.9, 1.04), fancybox=True, shadow=True)\n",
    "    plt.title(\"Country Sensitivity\", fontsize=8)\n",
    "    \n",
    "    \n",
    "ax5 = plt.subplot(gs.new_subplotspec((0, 2), colspan=1, rowspan=1))\n",
    "setup_small_plot(False, xlabel=False)\n",
    "plt.title(\"Death Delay\", fontsize=8)\n",
    "\n",
    "v = cat_sen[\"Death Delay\"]\n",
    "v.sort(key=lambda x:x[0])\n",
    "y_off = np.linspace(-0.4, 0.4, len(v)+1)\n",
    "width=1\n",
    "for j, (f, res) in enumerate(v):\n",
    "    add_trace_to_plot(res, y_off[j], col=colors[j], label=fname_to_label(f), alpha=1, width=width)\n",
    "add_trace_to_plot(default_res, y_off[-1], \"k\", \"Default\", 1, width)\n",
    "plt.legend(fontsize=6, loc=\"upper left\", bbox_to_anchor=(0.9, 1.04), fancybox=True, shadow=True)\n",
    "\n",
    "ax6 = plt.subplot(gs.new_subplotspec((0, 3), colspan=1, rowspan=1))\n",
    "setup_small_plot(False, xlabel=False)\n",
    "plt.title(\"Confirmed Delay\", fontsize=8)\n",
    "\n",
    "v = cat_sen[\"Cases Delay\"]\n",
    "v.sort(key=lambda x:x[0])\n",
    "y_off = np.linspace(-0.4, 0.4, len(v)+1)\n",
    "width=1\n",
    "for j, (f, res) in enumerate(v):\n",
    "    add_trace_to_plot(res, y_off[j], col=colors[j], label=fname_to_label(f), alpha=1, width=width)\n",
    "add_trace_to_plot(default_res, y_off[-1], \"k\", \"Default\", 1, width)\n",
    "plt.legend(fontsize=6, loc=\"upper left\", bbox_to_anchor=(0.9, 1.04), fancybox=True, shadow=True)\n",
    "\n",
    "ax7 = plt.subplot(gs.new_subplotspec((1, 2), colspan=1, rowspan=1))\n",
    "setup_small_plot(False, xlabel=False)\n",
    "plt.title(\"Effectiveness Prior\", fontsize=8)\n",
    "\n",
    "v = cat_sen[\"NPI Priors\"]\n",
    "v.sort(key=lambda x:x[0])\n",
    "y_off = np.linspace(-0.4, 0.4, len(v)+1)\n",
    "width=1\n",
    "for j, (f, res) in enumerate(v):\n",
    "    add_trace_to_plot(res, y_off[j], col=colors[j], label=fname_to_label(f), alpha=1, width=width)\n",
    "add_trace_to_plot(default_res, y_off[-1], \"k\", \"Default\", 1, width)\n",
    "    \n",
    "plt.legend(fontsize=6, loc=\"upper left\", bbox_to_anchor=(0.9, 1.04), fancybox=True, shadow=True)\n",
    "\n",
    "\n",
    "ax8 = plt.subplot(gs.new_subplotspec((1, 3), colspan=1, rowspan=1))\n",
    "setup_small_plot(False, xlabel=False)\n",
    "plt.title(\"Generation Interval\", fontsize=8)\n",
    "\n",
    "v = cat_sen[\"Serial Interval\"]\n",
    "v.sort(key=lambda x:x[0])\n",
    "y_off = np.linspace(-0.4, 0.4, len(v)+1)\n",
    "width=1\n",
    "for j, (f, res) in enumerate(v):\n",
    "    add_trace_to_plot(res, y_off[j], col=colors[j], label=fname_to_label(f), alpha=1, width=width)\n",
    "add_trace_to_plot(default_res, y_off[-1], \"k\", \"$\\mu = 6.67$\", 1, width)\n",
    "plt.legend(fontsize=6, loc=\"upper left\", bbox_to_anchor=(0.9, 1.04), fancybox=True, shadow=True)\n",
    "\n",
    "ax4 = plt.subplot(gs.new_subplotspec((2, 2), colspan=2, rowspan=2))\n",
    "setup_larger_plot(False)\n",
    "y_off = -np.linspace(-0.2, 0.2, 3)\n",
    "width = 2\n",
    "add_trace_to_plot(res_active.CMReduction, y_off[0], colors[0], \"Confirmed Cases\", 1, width) \n",
    "add_trace_to_plot(res_death.CMReduction, y_off[1], colors[1], \"Confirmed Deaths\", 1, width) \n",
    "add_trace_to_plot(default_res, y_off[2], \"k\", \"Default\", 1, width)\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.2, 1.01), fontsize=10)\n",
    "plt.title(\"Data Source\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"FigureMC.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ranking plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 10):\n",
    "    np.savetxt(f\"exp{i}.txt\", load_exp(i).CMReduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"exp18.txt\", load_exp(18).CMReduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"exp17.txt\", load_exp(17, True).CMReduction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_unis_lo = load_exp(20, True).CMReduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_unis_lo[:, 6] = default_res[:, 6]\n",
    "schools_unis_lo[:, 7] = default_res[:, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"exp20.txt\", load_exp(17, True).CMReduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_add = 1\n",
    "exp_noisyr = 2\n",
    "exp_diff = 3\n",
    "exp_dr = 4\n",
    "\n",
    "exp_travel = 5\n",
    "exp_transport = 6\n",
    "exp_int_movement = 7\n",
    "exp_info = 8\n",
    "exp_testing = 9\n",
    "\n",
    "exp_schools_uni = 20\n",
    "\n",
    "exp_active = 18\n",
    "exp_death = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_res = [load_exp(exp_add).CMReduction, load_exp(exp_noisyr, local=True).CMReduction, load_exp(exp_diff).CMReduction, load_exp(exp_dr).CMReduction, \n",
    "           load_exp(exp_travel).CMReduction, load_exp(exp_transport).CMReduction, load_exp(exp_int_movement).CMReduction, load_exp(exp_info).CMReduction, \n",
    "           load_exp(exp_testing).CMReduction, load_exp(exp_active).CMReduction, load_exp(exp_death).CMReduction,\n",
    "           load_exp(17, True).CMReduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_i, r in enumerate(data.Rs):\n",
    "    res = pickle.load(open(f\"../../server/ho_results_final4/{r}.pkl\", \"rb\")).CMReduction\n",
    "    np.savetxt(f\"regholdout{r}.txt\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_res = [pickle.load(open(f\"../../server/ho_results_final4/{r}.pkl\", \"rb\")) for r in data.Rs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_exps = [exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nCMs = 9\n",
    "\n",
    "def grab_all_rankings(fname, verbose=False):\n",
    "    global default_res\n",
    "    \n",
    "    files_found = 0\n",
    "    all_ranks = []\n",
    "    all_names = []\n",
    "    cat_sen = defaultdict(list)\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(walk(fname)):\n",
    "        for f in filenames:\n",
    "            if (\"_combined\" in f or \"exp\" in f or \"regholdout\" in f) and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f and \"base\" not in f:\n",
    "                trace = np.loadtxt(dirpath+\"/\"+f)\n",
    "                nS, f_nCMs = trace.shape\n",
    "                \n",
    "                if f_nCMs > nCMs:\n",
    "                    trace = trace[:, :nCMs]\n",
    "                elif f_nCMs < nCMs:\n",
    "                    leaveout_num = int(f[-5])\n",
    "                    full_trace = np.zeros((nS, nCMs))\n",
    "                    full_trace[:, :leaveout_num] = trace[:, :leaveout_num]\n",
    "                    full_trace[:, leaveout_num] = default_res[:, leaveout_num]\n",
    "                    full_trace[:, leaveout_num] = np.ones(nS)\n",
    "                    full_trace[:, (leaveout_num+1):] = trace[:, leaveout_num:]\n",
    "                    trace = full_trace\n",
    "                \n",
    "                files_found += 1\n",
    "                \n",
    "                res = trace\n",
    "                nS, _ = res.shape\n",
    "                \n",
    "                nF = len(derived_features)\n",
    "                derived_samples = np.zeros((nS, nF))\n",
    "                all_names.append(f)\n",
    "                for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "                    samples = np.ones(nS)\n",
    "                    for r in prodrows:\n",
    "                        samples = samples * res[:, r] \n",
    "                    derived_samples[:, f_i] = samples\n",
    "\n",
    "                res = derived_samples\n",
    "                ranks = rankdata(np.median(res, axis=0), method=\"min\")\n",
    "                all_ranks.append(ranks)\n",
    "      \n",
    "    return all_ranks, all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ranks, all_names = grab_all_rankings(\"../../server/traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_mat = np.array(all_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nT, nCMs = rank_mat.shape\n",
    "freq_mat = np.zeros((nCMs, nCMs))\n",
    "\n",
    "for cm in range(nCMs):\n",
    "    for rank in range(nCMs):\n",
    "        freq_mat[cm, rank] = np.sum(rank_mat[:, cm] == (rank+1)) /  nT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "im = plt.imshow(100*freq_mat, vmin=0, vmax=100)\n",
    "plt.xticks(np.arange(nCMs), np.arange(nCMs)+1, fontsize=8)\n",
    "plt.xlabel(\"NPI Median Effectiveness Ranking\")\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.yticks(np.arange(nCMs), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "yax = ax.get_yaxis()\n",
    "yax.set_tick_params(pad=140)\n",
    "\n",
    "\n",
    "for cm in range(len(derived_features)):\n",
    "    for i, val in enumerate(derived_features[cm][1]):\n",
    "        plt.text(8+0.6*i, cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                     fontproperties=fp2, fontsize=8, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "\n",
    "ax.invert_xaxis()\n",
    "plt.title(\"Global NPI Rank Stability\", fontsize=10)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbr = plt.colorbar(im, cax=cax, format=PercentFormatter())\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=6)\n",
    "cbr.set_ticks([25, 50, 75, 100])\n",
    "plt.savefig(f\"FigureGlobalStability.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_names(names):\n",
    "    cs = defaultdict(lambda: 0)\n",
    "\n",
    "    for f in names:\n",
    "        if \"regholdout\" in f:\n",
    "            cs[\"region holdouts\"] += 1\n",
    "        \n",
    "        if \"cm_prior\" in f:\n",
    "            cs[\"npi priors\"] += 1\n",
    "        \n",
    "        if \"min_deaths\" in f:\n",
    "            cs[\"death threshold\"] += 1\n",
    "        \n",
    "        if \"delay_mean_confirmed\" in f:\n",
    "            cs[\"delay confirmation\"] += 1\n",
    "        \n",
    "        if \"smoothing\" in f:\n",
    "            cs[\"smoothing\"] += 1\n",
    "        \n",
    "        if \"growth_noise\" in f:\n",
    "            cs[\"hypers\"] += 1\n",
    "            \n",
    "        if \"leavout\" in f or \"exp20\" in f:\n",
    "            cs[\"leavouts\"] += 1\n",
    "            \n",
    "        if \"serial_int\" in f:\n",
    "            cs[\"gis\"] += 1\n",
    "            \n",
    "        if \"min_confirmed\" in f:\n",
    "            cs[\"conf threshold\"] += 1\n",
    "            \n",
    "        if \"delay_mean_death\" in f:\n",
    "            cs[\"death delay\"] += 1\n",
    "            \n",
    "        if \"R_hyperprior\" in f:\n",
    "            cs[\"R hyper\"] += 1   \n",
    "        \n",
    "        if \"exp02\" in f or \"exp01\" in f or \"exp03\" in f or \"exp04\" in f:\n",
    "            cs[\"struct sens\"] += 1\n",
    "            \n",
    "        if \"exp5\" in f or \"exp6\" in f or \"exp7\" in f or \"exp8\" in f or \"exp9\" in f:\n",
    "            cs[\"oxcgrt checks\"] += 1\n",
    "            \n",
    "        if \"exp18\" in f or \"exp19\" in f:\n",
    "            cs[\"data source\"] += 1\n",
    "        \n",
    "        if \"exp17\" in f:\n",
    "            cs[\"agg holdout\"] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = categorise_names(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in vals.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(list(vals.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(vals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
